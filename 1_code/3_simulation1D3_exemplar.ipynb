{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "123d9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3_simulation1D1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn as sk\n",
    "from skopt import gp_minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import Matern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d104211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions --------------------------------------------------------------------\n",
    "# Generate observed data\n",
    "def generateObservedData(sampleSize, w, gamma):\n",
    "    intercept = np.ones(sampleSize)\n",
    "    X = w*np.random.uniform(0, 1, sampleSize)\n",
    "    A = random.choices([0, 1], weights = [0.5, 0.5], k = sampleSize)\n",
    "    Y = gamma[0]*intercept + gamma[1]*X + A*np.cos(X*2*np.pi)\n",
    "    return intercept, X, A, Y\n",
    "    \n",
    "# IPW estimate (negated)\n",
    "def computeIPW(beta, obsData, n):\n",
    "    obsData['A_d'] = np.logical_or(obsData['X'] < beta[0], obsData['X'] > beta[1])*1.0\n",
    "    obsData['C_d'] = np.where(obsData['A'] == obsData['A_d'], 1, 0)\n",
    "    obsData['pi_d'] = 0.5\n",
    "    obsData['summand'] = obsData['C_d']*obsData['Y']/obsData['pi_d']\n",
    "    \n",
    "    # Estimate the value\n",
    "    vhat_ipw = sum(obsData['summand'])/(n)\n",
    "    \n",
    "    return -1*vhat_ipw\n",
    "\n",
    "# Stabilized IPW estimate (negated)\n",
    "def computeStabilizedIPW(beta, obsData, n):\n",
    "    obsData['A_d'] = np.logical_or(obsData['X'] < beta[0], obsData['X'] > beta[1])*1.0\n",
    "    obsData['C_d'] = np.where(obsData['A'] == obsData['A_d'], 1, 0)\n",
    "    obsData['pi_d'] = 0.5\n",
    "    obsData['summand'] = obsData['C_d']*obsData['Y']*obsData['pi_d']\n",
    "    \n",
    "    # Estimate the value\n",
    "    vhat_stabilizedIPW = sum(obsData['summand'])/(sum(obsData['C_d']*obsData['pi_d']))\n",
    "    \n",
    "    return -1*vhat_stabilizedIPW\n",
    "\n",
    "# Regression estimator (G-computation) (negated)\n",
    "def computeRegEst(beta, obsData, n):\n",
    "    # X contains the covariates\n",
    "    X = obsData.loc[:,['X', 'A']]\n",
    "    X['int'] = np.ones(n)\n",
    "    X['AX'] = np.multiply(obsData['X'], obsData['A'])\n",
    "    X = X.loc[:, ['int', 'X', 'A', 'AX']]\n",
    "    \n",
    "    # Y contains the outcomes\n",
    "    Y = obsData['Y']\n",
    "    \n",
    "    # Fit the regression model\n",
    "    model = LinearRegression().fit(X, Y)\n",
    "    \n",
    "    # Calculate Qhat(H, 1)\n",
    "    X_1 = X.copy(deep = True)\n",
    "    X_1['A'] = 1\n",
    "    Qhat1 = model.predict(X_1)\n",
    "    \n",
    "    # Calculate Qhat(H, 0)\n",
    "    X_0 = X.copy(deep = True)\n",
    "    X_0['A'] = 0\n",
    "    Qhat0 = model.predict(X_0)\n",
    "    \n",
    "    # Calculate the treatment recommendation under the policy indexed by beta\n",
    "    A_d = np.logical_or(obsData['X'] < beta[0], obsData['X'] > beta[1])*1.0\n",
    "    \n",
    "    # Estimate the value\n",
    "    vhat = np.sum(np.where(A_d == 1, Qhat1, 0) + np.where(A_d == 0, Qhat0, 0))*(1/n)\n",
    "    \n",
    "    return -1*vhat\n",
    "\n",
    "# AIPWE (negated)\n",
    "def computeAIPWE(beta, obsData, n):\n",
    "    # IPW piece\n",
    "    obsData['A_d'] = np.logical_or(obsData['X'] < beta[0], obsData['X'] > beta[1])*1.0\n",
    "    obsData['C_d'] = np.where(obsData['A'] == obsData['A_d'], 1, 0)\n",
    "    obsData['pi_d'] = 0.5\n",
    "#     obsData['summand'] = obsData['C_d']*obsData['Y']*obsData['pi_d']\n",
    "#     obsData['weight'] = (obsData['C_d'] - obsData['pi_d'])/obsData['pi_d']\n",
    "    \n",
    "    # Regression piece\n",
    "    # X contains the covariates\n",
    "    X = obsData.loc[:,['X', 'A']]\n",
    "    X['int'] = np.ones(n)\n",
    "    X['AX'] = np.multiply(obsData['X'], obsData['A'])\n",
    "    X = X.loc[:, ['int', 'X', 'A', 'AX']]\n",
    "    \n",
    "    # Y contains the outcomes\n",
    "    Y = obsData['Y']\n",
    "    \n",
    "    # Fit the regression model\n",
    "    model = LinearRegression().fit(X, Y)\n",
    "    \n",
    "    # Calculate Qhat(H, 1)\n",
    "    X_1 = X.copy(deep = True)\n",
    "    X_1['A'] = 1\n",
    "    Qhat1 = model.predict(X_1)\n",
    "    \n",
    "    # Calculate Qhat(H, 0)\n",
    "    X_0 = X.copy(deep = True)\n",
    "    X_0['A'] = 0\n",
    "    Qhat0 = model.predict(X_0)\n",
    "    \n",
    "    # Calculate the treatment recommendation under the policy indexed by beta\n",
    "    A_d = np.logical_or(obsData['X'] < beta[0], obsData['X'] > beta[1])*1.0\n",
    "    \n",
    "    # Calculate the pseudo value\n",
    "    obsData['yhat'] = np.where(A_d == 1, Qhat1, 0) + np.where(A_d == 0, Qhat0, 0)\n",
    "    \n",
    "    # Estimate the value\n",
    "#     vhat = (1/n)*sum(obsData['summand'] - obsData['weight']*obsData['yhat'])\n",
    "    vhat = (1/n)*sum(obsData['yhat']) + (1/n)*sum((obsData['C_d']/obsData['pi_d'])*(obsData['Y'] - obsData['yhat']))\n",
    "    \n",
    "    return -1*vhat\n",
    "    \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de80ce7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:506: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n"
     ]
    }
   ],
   "source": [
    "# Simulation code --------------------------------------------------------------\n",
    "for w in [0.75, 1, 1.25]:\n",
    "    for nObs in [200, 500, 1000]:\n",
    "        for evaluationEstimator in ['IPW', 'sIPW', 'AIPWE', 'gcomp']:\n",
    "            \n",
    "\n",
    "            # Read in the true values for the evaluation of the GP\n",
    "            trueValues = pd.read_csv('../2_pipeline/3_simulation1D3_'+str(w)+'_trueValues.csv')\n",
    "            outFileName = '3_simulation1D3_'+str(evaluationEstimator)+'_'+str(nObs)+'_'+str(w)+'_exemplar.csv'\n",
    "            outFileName2 = '3_simulation1D3_'+str(evaluationEstimator)+'_'+str(nObs)+'_'+str(w)+'_exemplarPred.csv'\n",
    "\n",
    "            # Places to hold the things we want to keep\n",
    "            optDTR_param_holder = []\n",
    "            optDTR_value_holder = []\n",
    "            L_holder = []\n",
    "            norm_sup_holder = []\n",
    "            norm_1_holder = []\n",
    "            norm_2_holder = []\n",
    "            beta0_holder = []\n",
    "            beta1_holder =[]\n",
    "            pred_holder = []\n",
    "\n",
    "            # Set the seed -------------------------------------\n",
    "            np.random.seed(1234) # First from each simulation run\n",
    "\n",
    "\n",
    "            # Generate simulation data set ---------------------\n",
    "            # Parameters for data generation\n",
    "            gamma = [-0.5, 1]\n",
    "            obsData = generateObservedData(nObs, w, gamma)\n",
    "            obsData = pd.DataFrame(obsData).transpose()\n",
    "\n",
    "            # Tidy up the dataframe with the \"observed data\"\n",
    "            obsData = obsData.rename(columns = {0:'intercept', 1:'X', 2:'A', 3:'Y'})\n",
    "\n",
    "            # Bayesian optimization ------------------------------\n",
    "            noise = 0.01\n",
    "            if evaluationEstimator == 'IPW':\n",
    "                def computeIPW_internal(beta, obsData = obsData, nObs = nObs):\n",
    "                    return computeIPW(beta, obsData = obsData, n = nObs)\n",
    "                ei_result = gp_minimize(computeIPW_internal,\n",
    "                           [(0.0, 1.0), (0.0, 1.0)],\n",
    "                           acq_func = \"EI\",\n",
    "                           n_calls = 50,\n",
    "                           n_random_starts = 50,\n",
    "                           noise = noise)\n",
    "            if evaluationEstimator == \"sIPW\":\n",
    "                def computeStabilizedIPW_internal(beta, obsData = obsData, nObs = nObs):\n",
    "                    return computeStabilizedIPW(beta, obsData = obsData, n = nObs)\n",
    "                ei_result = gp_minimize(computeStabilizedIPW_internal,\n",
    "                           [(0.0, 1.0), (.0, 1.0)],\n",
    "                           acq_func = \"EI\",\n",
    "                           n_calls = 50,\n",
    "                           n_random_starts = 50,\n",
    "                           noise = noise)\n",
    "            if evaluationEstimator == \"gcomp\":\n",
    "                def computeRegEst_internal(beta, obsData = obsData, nObs = nObs):\n",
    "                    return computeRegEst(beta, obsData = obsData, n = nObs)\n",
    "                ei_result = gp_minimize(computeRegEst_internal,\n",
    "                           [(0.0, 1.0), (0.0, 1.0)],\n",
    "                           acq_func = \"EI\",\n",
    "                           n_calls = 50,\n",
    "                           n_random_starts = 50,\n",
    "                           noise = noise)\n",
    "            if evaluationEstimator == \"AIPWE\":\n",
    "                def computeAIPWE_internal(beta, obsData = obsData, nObs = nObs):\n",
    "                    return computeAIPWE(beta, obsData = obsData, n = nObs)\n",
    "                ei_result = gp_minimize(computeAIPWE_internal,\n",
    "                           [(0.0, 1.0), (0.0, 1.0)],\n",
    "                           acq_func = \"EI\",\n",
    "                           n_calls = 50,\n",
    "                           n_random_starts = 50,\n",
    "                           noise = noise)\n",
    "            # Extract the relevant information\n",
    "            optDTR_param = ei_result['x']\n",
    "            optDTR_value = ei_result['fun']\n",
    "            evaluation_X = ei_result['x_iters']\n",
    "            evaluation_Y = ei_result['func_vals']\n",
    "\n",
    "            # Fit a GP to the evaluation points --------------------\n",
    "            kernel = 1.0 * Matern(length_scale = [1.0, 1.0], nu = 1.0) \\\n",
    "                + WhiteKernel(noise_level = 10, noise_level_bounds = (1e-10, 1e2))\n",
    "            gpr = GaussianProcessRegressor(kernel = kernel, alpha = 0.0)\n",
    "            gpr.fit(evaluation_X, evaluation_Y)\n",
    "\n",
    "            # Get predictions across a fine grid of the parameter space\n",
    "            diffs = []\n",
    "            for i in range(trueValues.shape[0]):\n",
    "                pred = gpr.predict(np.array(trueValues.loc[i, ['beta0', 'beta1']]).reshape(1, -1))\n",
    "                diffs.append(-1*pred - trueValues.loc[i, 'value'])\n",
    "                beta0_holder.append(trueValues.loc[i, ['beta0']][0])\n",
    "                beta1_holder.append(trueValues.loc[i, ['beta1']][0])\n",
    "                pred_holder.append(pred[0])\n",
    "            # Compute the distance between the prediction and the Truth (actual truth, not the evaluation truth)    \n",
    "            norm_sup = max(np.abs(diffs))\n",
    "            norm_1 = np.mean(np.abs(diffs))\n",
    "            norm_2 = np.sqrt(sum(np.abs(diffs)**2)*(1/trueValues.shape[0]))\n",
    "\n",
    "            # Update the holder lists\n",
    "            optDTR_param_holder.append(optDTR_param)\n",
    "            optDTR_value_holder.append(optDTR_value)\n",
    "            norm_sup_holder.append(norm_sup)\n",
    "            norm_1_holder.append(norm_1)\n",
    "            norm_2_holder.append(norm_2)\n",
    "\n",
    "            # Convert the list of arrays to a list\n",
    "            norm_sup_holder = [i[0] for i in norm_sup_holder]\n",
    "            norm_2_holder = [i[0] for i in norm_2_holder]\n",
    "\n",
    "            # Put the lists into a data frame\n",
    "            out1 = pd.DataFrame({'optDTR_value':optDTR_value_holder, 'norm_sup':norm_sup_holder,\n",
    "                                 'norm_1':norm_1_holder, 'norm_2':norm_2_holder})\n",
    "            out2 = pd.DataFrame(optDTR_param_holder, columns = ['beta0', 'beta1'])\n",
    "            out = pd.concat([out1, out2], axis = 1)\n",
    "\n",
    "            out.to_csv('../2_pipeline/'+outFileName)\n",
    "\n",
    "            diffs = [i.tolist() for i in diffs]\n",
    "            diffs = [i[0] for i in diffs]\n",
    "            pred_out = pd.DataFrame({'beta0':beta0_holder, 'beta1':beta1_holder, 'pred':pred_holder, 'diff':diffs})\n",
    "            pred_out.to_csv('../2_pipeline/'+outFileName2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "17e41bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta0</th>\n",
       "      <th>beta1</th>\n",
       "      <th>pred</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.019668</td>\n",
       "      <td>-0.009813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>-0.003416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.025014</td>\n",
       "      <td>0.003588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.028342</td>\n",
       "      <td>0.009938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.032338</td>\n",
       "      <td>0.015299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.076374</td>\n",
       "      <td>-0.066518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.080358</td>\n",
       "      <td>-0.070502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.083849</td>\n",
       "      <td>-0.073993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.086880</td>\n",
       "      <td>-0.077024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10200</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.089488</td>\n",
       "      <td>-0.079632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10201 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       beta0  beta1      pred      diff\n",
       "0        0.0   0.00  0.019668 -0.009813\n",
       "1        0.0   0.01  0.022166 -0.003416\n",
       "2        0.0   0.02  0.025014  0.003588\n",
       "3        0.0   0.03  0.028342  0.009938\n",
       "4        0.0   0.04  0.032338  0.015299\n",
       "...      ...    ...       ...       ...\n",
       "10196    1.0   0.96  0.076374 -0.066518\n",
       "10197    1.0   0.97  0.080358 -0.070502\n",
       "10198    1.0   0.98  0.083849 -0.073993\n",
       "10199    1.0   0.99  0.086880 -0.077024\n",
       "10200    1.0   1.00  0.089488 -0.079632\n",
       "\n",
       "[10201 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
